{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notation in math \n",
    "$x, y \\in \\mathbb{R}$, means that they are scalar \n",
    "\n",
    "$x, y \\in {0, 1}$ means that x, y can only be 0 or 1\n",
    "\n",
    "$\\textbf{x}$ bold text represents vector, $x_2$ represents second scalar inside the vector. \n",
    "\n",
    "$\\textbf{A}, \\textbf{B} \\in \\mathbb{R}^{m \\times n}$, represents two matrixes. \n",
    "\n",
    "$\\textbf{A} \\odot \\textbf{B}$ = element-wise multiplication to matrixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 3,\n",
       " torch.Size([3]),\n",
       " tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[[0]],\n",
       " \n",
       "         [[1]],\n",
       " \n",
       "         [[2]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## some useful helper function to vectors in pytoch\n",
    "x = torch.arange(3)\n",
    "len(x), x.shape[0], x.shape, x.reshape(1, 3).T, x.reshape(3, 1), x.reshape(3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## some useful helper function of matrix in pytoch \n",
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些对于tensor的理解。\n",
    "\n",
    "原始的理解：他就是连续的bytes的排列，只不过行列的堆叠正好成为了matrix的形状，方便被数学形式化。\n",
    "\n",
    "一个例子：\n",
    "> 开始处理图像时，张量将变得更加重要。每幅图像都以\n",
    "阶张量，轴对应于高度、宽度和通道。在每个空间位置，每种颜色（红色、绿色和蓝色）的强度沿通道堆叠。此外，一组图像在代码中表示为\n",
    "阶张量，其中不同的图像沿第一个轴进行索引。高阶张量是通过增加形状分量的数量来构建的，就像向量和矩阵一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), torch.Size([2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix\n",
    "A.shape, A.sum(axis=0).shape, A.sum(axis=1).shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]),\n",
       " torch.Size([3, 4]),\n",
       " torch.Size([2, 4]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img \n",
    "B = torch.arange(24, dtype=torch.float32).reshape(2, 3, 4)\n",
    "B.shape, B.sum(axis=0).shape, B.sum(axis=1).shape, B.sum(axis=2).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子理解\n",
    "$\\textbf{B} \\in \\mathbb{R}^{2 \\times 3 \\times 4 \\times 5}$, 看作是一个视频，那么\n",
    "\n",
    "```np.operator(axis=0)``` -> 代表我们对每一个视频帧自己进行operator reduce操作，最后只剩下一个视频帧。\n",
    "\n",
    "```np.operator(axis=1)``` -> 代表我们对每一个视频帧中的每个channel进行operator reduce操作，最后剩下2个视频帧，但是丢失了channel。\n",
    "\n",
    "```np.operator(axis=2)``` -> \n",
    "\n",
    "```np.operator(axis=3)``` -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4, 5]),\n",
       " torch.Size([3, 4, 5]),\n",
       " torch.Size([2, 4, 5]),\n",
       " torch.Size([2, 3, 5]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# video \n",
    "B = torch.arange(2 * 3 * 4 * 5, dtype=torch.float32).reshape(2, 3, 4, 5)\n",
    "B.shape, B.sum(axis=0).shape, B.sum(axis=1).shape, B.sum(axis=2).shape, B.sum(axis=3).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()  # Same as A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一些operator \n",
    "A.sum(axis=[0, 1]), A.mean(), A.sum() / A.numel(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 119.]]]]),\n",
       " tensor([[[20., 21., 22., 23., 24.],\n",
       "          [25., 26., 27., 28., 29.],\n",
       "          [30., 31., 32., 33., 34.],\n",
       "          [35., 36., 37., 38., 39.]],\n",
       " \n",
       "         [[80., 81., 82., 83., 84.],\n",
       "          [85., 86., 87., 88., 89.],\n",
       "          [90., 91., 92., 93., 94.],\n",
       "          [95., 96., 97., 98., 99.]]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exec：对视频操作\n",
    "B = torch.arange(2 * 3 * 4 * 5, dtype=torch.float32).reshape(2, 3, 4, 5)\n",
    "# 对channel取均值\n",
    "B, B.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some generally useful opeartaion of reduction\n",
    "\n",
    "# 1. normallize\n",
    "A /= A.sum()\n",
    "\n",
    "# 2. normalize across certain axis (it performs broadcast) \n",
    "A /= A.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot prod and matrix prod\n",
    "dot prod = inner prod = $\\langle \\textbf{x}, \\textbf{y} \\rangle= \\textbf{x}^T \\textbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([2., 2., 2.]), tensor(6.))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## About dot \n",
    "x = torch.arange(3, dtype = torch.float32)\n",
    "y = torch.ones(3, dtype = torch.float32) * 2\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some norm: $\\textbf{A} \\in \\mathbb{R}^{M \\times N}$. And $\\textbf{A}\\textbf{x}$ is a transformation of dim $N$ to $M$ \n",
    "\n",
    "personal notes: 大多数情况matrix都要想成是vectors的集合，比如features，imges的个数，channel。而理解matrix为什么要这么乘至关重要 -- 为了清理？为了归一化？为了non-linear一下？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),\n",
       " torch.Size([4]),\n",
       " tensor([14., 38., 62.]),\n",
       " tensor([14., 38., 62.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## matrix transformation \n",
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A, x), A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm\n",
    "A norm is a function that maps a vector to a scalar and satisfies the following three properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "# l2, and l1 norm\n",
    "torch.norm(u),torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
